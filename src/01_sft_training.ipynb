{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM 수리추론 능력 강화를 위한 SFT 학습\n",
        "\n",
        "## 실험 개요\n",
        "- **목적**: SFT를 활용한 LLM 수리추론 능력 강화\n",
        "- **학습 데이터**: grade-school-math-instructions\n",
        "- **평가 데이터**: math-QA (lm-evaluation-harness)\n",
        "- **학습 모델**: Qwen2.5-0.5B, Qwen2.5-1.5B (base models)\n",
        "- **환경**: Colab T4 GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 설정\n",
        "\n",
        "### 의존성 버전 (테스트 완료)\n",
        "| 패키지 | 버전 | 용도 |\n",
        "|--------|------|------|\n",
        "| torch | 2.4.0+ | 딥러닝 프레임워크 |\n",
        "| transformers | 4.44.2+ | 모델 로딩 |\n",
        "| datasets | 2.21.0 | 데이터 로딩 |\n",
        "| accelerate | 0.33.0+ | 분산 학습 |\n",
        "| peft | 0.12.0 | LoRA/QLoRA |\n",
        "| bitsandbytes | 0.43.3+ | 4-bit quantization |\n",
        "| trl | 0.9.6 | SFT Trainer |\n",
        "| wandb | 0.17.5+ | 실험 추적 |\n",
        "| flash-attn | 2.5.0+ | **속도 최적화 (선택)** |\n",
        "| scipy | 1.13.1 | 수치 연산 |\n",
        "\n",
        "### 속도 최적화 패키지\n",
        "Flash Attention 2를 사용하려면 별도 설치가 필요합니다:\n",
        "```bash\n",
        "pip install flash-attn --no-build-isolation\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ⚠️ triton/GenerationMixin 오류 시 (Colab)\n",
        "\n",
        "`triton.backends` 또는 `GenerationMixin` import 오류가 나면:\n",
        "\n",
        "1. **아래 셀 실행** → triton 업그레이드 + transformers 재설치\n",
        "2. **런타임 재시작** (Runtime → Restart runtime) ← **필수!**\n",
        "3. 노트북 처음부터 다시 실행\n",
        "\n",
        "**`KernelMetadata.cluster_dims` 오류 시**: `torch_compile=True`가 PyTorch inductor/Triton과 충돌합니다. `get_training_args()`에서 `torch_compile=False`로 설정되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.5.0)\n",
            "Collecting triton\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.9.0+cu126 requires triton==3.5.0; platform_system == \"Linux\", but you have triton 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed triton-3.6.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "f99c039943a04f85bdc9a25eb753c363",
              "pip_warning": {
                "packages": [
                  "triton"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets==2.21.0\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (0.70.16)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==2.21.0)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (1.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.21.0) (6.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.21.0) (1.22.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.21.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.21.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.21.0) (2025.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.21.2->datasets==2.21.0) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.21.2->datasets==2.21.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.21.2->datasets==2.21.0) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.21.0) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.21.2->datasets==2.21.0) (8.3.1)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.9.0+cu126 requires triton==3.5.0; platform_system == \"Linux\", but you have triton 3.6.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 fsspec-2024.6.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "f053490ed6864a03894135d5d70d65ac",
              "pip_warning": {
                "packages": [
                  "datasets",
                  "fsspec"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting peft==0.12.0\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (5.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (1.12.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (0.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.12.0) (1.3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2024.6.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.12.0) (1.11.1.6)\n",
            "Collecting triton==3.5.0 (from torch>=1.13.0->peft==0.12.0)\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.12.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.12.0) (0.22.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.17.0->peft==0.12.0) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.17.0->peft==0.12.0) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.17.0->peft==0.12.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.17.0->peft==0.12.0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.17.0->peft==0.12.0) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.12.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.12.0) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.17.0->peft==0.12.0) (8.3.1)\n",
            "Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, peft\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.6.0\n",
            "    Uninstalling triton-3.6.0:\n",
            "      Successfully uninstalled triton-3.6.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.18.1\n",
            "    Uninstalling peft-0.18.1:\n",
            "      Successfully uninstalled peft-0.18.1\n",
            "Successfully installed peft-0.12.0 triton-3.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "d489bc2fa4c5489aaa7ac603639b5cfa",
              "pip_warning": {
                "packages": [
                  "peft",
                  "triton"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting trl==0.9.6\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.9.6) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.9.6) (5.0.0)\n",
            "Collecting numpy<2.0.0,>=1.18.2 (from trl==0.9.6)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from trl==0.9.6) (1.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from trl==0.9.6) (2.21.0)\n",
            "Collecting tyro>=0.5.11 (from trl==0.9.6)\n",
            "  Downloading tyro-1.0.5-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->trl==0.9.6) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->trl==0.9.6) (1.3.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->trl==0.9.6) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->trl==0.9.6) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->trl==0.9.6) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->trl==0.9.6) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->trl==0.9.6) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->trl==0.9.6) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->trl==0.9.6) (4.67.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro>=0.5.11->trl==0.9.6) (0.17.0)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro>=0.5.11->trl==0.9.6) (4.4.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->trl==0.9.6) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->trl==0.9.6) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->trl==0.9.6) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->trl==0.9.6) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets->trl==0.9.6) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->trl==0.9.6) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets->trl==0.9.6) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets->trl==0.9.6) (3.13.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets->trl==0.9.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets->trl==0.9.6) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets->trl==0.9.6) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets->trl==0.9.6) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets->trl==0.9.6) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets->trl==0.9.6) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets->trl==0.9.6) (1.22.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.31.0->trl==0.9.6) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.31.0->trl==0.9.6) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.31.0->trl==0.9.6) (1.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->trl==0.9.6) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->trl==0.9.6) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->trl==0.9.6) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->trl==0.9.6) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.4.0->trl==0.9.6) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.4.0->trl==0.9.6) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->trl==0.9.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->trl==0.9.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->trl==0.9.6) (2025.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers>=4.31.0->trl==0.9.6) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.31.0->trl==0.9.6) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.31.0->trl==0.9.6) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.31.0->trl==0.9.6) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.9.6) (1.17.0)\n",
            "Downloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tyro-1.0.5-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, tyro, trl\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 trl-0.9.6 tyro-1.0.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "992c30bfc1dc4d4881bf9d847f564c44",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from scipy==1.13.1) (1.26.4)\n",
            "Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "access 1.1.10.post3 requires scipy>=1.14.1, but you have scipy 1.13.1 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.13.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0b953fd888214c2581a43c55f9475ef3",
              "pip_warning": {
                "packages": [
                  "scipy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.24.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.46)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.51.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2026.1.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: accelerate>=1.7.0 in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.7.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.7.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.7.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.7.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.7.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.7.0) (1.3.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.7.0) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.7.0) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.7.0) (2024.6.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.7.0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.7.0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.7.0) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.7.0) (4.67.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.7.0) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.7.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.7.0) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.7.0) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.7.0) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.7.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.7.0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.7.0) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.7.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.7.0) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate>=1.7.0) (8.3.1)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.5.0)\n",
            "Collecting triton\n",
            "  Using cached triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Using cached triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "Installing collected packages: triton\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.9.0+cu126 requires triton==3.5.0; platform_system == \"Linux\", but you have triton 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed triton-3.6.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6e33073423c34aad806413f1a7e1bc3d",
              "pip_warning": {
                "packages": [
                  "triton"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 핵심 라이브러리 설치 (버전 명시)\n",
        "\n",
        "# 기본 라이브러리 설치\n",
        "!pip install transformers>=4.45.0 bitsandbytes>=0.44.0 \n",
        "!pip install --upgrade triton  # torch 2.9 호환 (2.2.0 고정 시 triton.backends 오류)\n",
        "!pip install datasets==2.21.0\n",
        "!pip install peft==0.12.0\n",
        "!pip install trl==0.9.6\n",
        "!pip install scipy==1.13.1\n",
        "# !pip install numpy pandas\n",
        "!pip install numpy --no-cache-dir\n",
        "!pip install wandb\n",
        "!pip install --upgrade \"accelerate>=1.7.0\"\n",
        "!pip install --upgrade triton\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # GPU 사용 확인\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: flash-attn\u001b[0m\u001b[33m\n",
            "\u001b[0mName: torch\n",
            "Version: 2.9.0+cu126\n",
            "Name: transformers\n",
            "Version: 4.57.6\n",
            "Name: datasets\n",
            "Version: 2.21.0\n",
            "Name: accelerate\n",
            "Version: 1.12.0\n",
            "Name: peft\n",
            "Version: 0.12.0\n",
            "Name: bitsandbytes\n",
            "Version: 0.49.1\n",
            "Name: trl\n",
            "Version: 0.9.6\n",
            "Name: wandb\n",
            "Version: 0.24.0\n"
          ]
        }
      ],
      "source": [
        "# 설치된 버전 확인\n",
        "!pip show torch transformers datasets accelerate peft bitsandbytes trl wandb flash-attn | grep -E \"^(Name|Version)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 라이브러리 임포트 및 Attention 구현 방식 설정\n",
        "\n",
        "필요한 라이브러리를 임포트하고, GPU 환경에 맞는 Attention 구현 방식(Flash Attention 2, SDPA, eager)을 자동으로 선택합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### WandB 실험 추적 설정\n",
        "\n",
        "Weights & Biases를 사용하여 학습 과정을 추적합니다. API 키로 로그인하고 프로젝트 이름을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ SDPA (Scaled Dot Product Attention) 사용\n",
            "Attention Implementation: sdpa\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# Attention 구현 방식 결정\n",
        "# - Flash Attention 2: Ampere (8.0) 이상 필요\n",
        "# - SDPA: PyTorch 2.0+에서 사용 가능, T4에서도 동작\n",
        "# - eager: 기본 구현\n",
        "def get_attn_implementation():\n",
        "    if not torch.cuda.is_available():\n",
        "        return \"eager\"\n",
        "    \n",
        "    major, minor = torch.cuda.get_device_capability()\n",
        "    compute_capability = float(f\"{major}.{minor}\")\n",
        "    \n",
        "    # Ampere (8.0) 이상이면 Flash Attention 2 사용\n",
        "    if compute_capability >= 8.0:\n",
        "        try:\n",
        "            import flash_attn\n",
        "            print(f\"✓ Flash Attention 2 사용 가능 (v{flash_attn.__version__})\")\n",
        "            return \"flash_attention_2\"\n",
        "        except ImportError:\n",
        "            pass\n",
        "    \n",
        "    # PyTorch 2.0+ 이면 SDPA 사용 (T4에서도 동작)\n",
        "    if torch.__version__ >= \"2.0\":\n",
        "        print(f\"✓ SDPA (Scaled Dot Product Attention) 사용\")\n",
        "        return \"sdpa\"\n",
        "    \n",
        "    print(\"✓ Eager Attention 사용\")\n",
        "    return \"eager\"\n",
        "\n",
        "ATTN_IMPLEMENTATION = get_attn_implementation()\n",
        "print(f\"Attention Implementation: {ATTN_IMPLEMENTATION}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load HF_TOKEN, WANDB_API_KEY, WANDB_ENTITY from .env (copy .env.example to .env and fill in)\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HuggingFace 로그인 및 데이터셋 로드\n",
        "\n",
        "HuggingFace Hub에 로그인하고 grade-school-math-instructions 데이터셋을 로드합니다. 이 데이터셋은 초등학교 수준의 수학 문제와 단계별 풀이를 포함합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 데이터 전처리\n",
        "\n",
        "INSTRUCTION과 RESPONSE 필드를 \"### Question:\" / \"### Answer:\" 형식으로 변환하여 모델 학습에 적합한 텍스트 포맷을 생성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 학습/검증 데이터 분할\n",
        "\n",
        "데이터셋을 90% 학습, 10% 검증으로 분할합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjungwoonshin\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "# WANDB_API_KEY, WANDB_ENTITY from .env (see .env.example)\n",
        "wandb_api_key = os.environ.get(\"WANDB_API_KEY\")\n",
        "if wandb_api_key:\n",
        "    wandb.login(key=wandb_api_key)\n",
        "else:\n",
        "    wandb.login()\n",
        "\n",
        "PROJECT_NAME = \"llm-math-reasoning-sft\"\n",
        "ENTITY = os.environ.get(\"WANDB_ENTITY\", \"jungwoonshin\")  # 본인의 wandb username 또는 team name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2caf0ea219b4f1495410016fbe798c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/852 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "965bcd69c25043cd8d55a9c667eb567c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.55M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ba4f4ab20ee45868f0a08bf9f831ec6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/8792 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['INSTRUCTION', 'RESPONSE', 'SOURCE'],\n",
            "        num_rows: 8792\n",
            "    })\n",
            "})\n",
            "\n",
            "Sample data:\n",
            "{'INSTRUCTION': 'This math problem has got me stumped: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\nCan you show me the way?', 'RESPONSE': 'Natalia sold 48/2 = 24 clips in May.\\nNatalia sold 48+24 = 72 clips altogether in April and May.', 'SOURCE': 'grade-school-math'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# HF_TOKEN from .env (see .env.example)\n",
        "import os\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "from huggingface_hub import login\n",
        "\n",
        "if HF_TOKEN:\n",
        "    login(token=HF_TOKEN)\n",
        "\n",
        "# Grade School Math Instructions 데이터셋 로드\n",
        "dataset = load_dataset(\"qwedsacf/grade-school-math-instructions\")\n",
        "print(f\"Dataset structure: {dataset}\")\n",
        "print(f\"\\nSample data:\")\n",
        "print(dataset['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c2fb1dfd7ba43df9435c2486fc234c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8792 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formatted dataset size: 8792\n",
            "\n",
            "Sample formatted data:\n",
            "### Question:\n",
            "This math problem has got me stumped: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
            "Can you show me the way?\n",
            "\n",
            "### Answer:\n",
            "Natalia sold 48/2 = 24 clips in May.\n",
            "Natalia sold 48+24 = 72 clips altogether in April and May.\n"
          ]
        }
      ],
      "source": [
        "# 데이터 전처리 함수\n",
        "def format_instruction(sample):                                                                                                                                                                            \n",
        "    instruction = sample.get('INSTRUCTION', '')                                                                                                                                                            \n",
        "    response = sample.get('RESPONSE', '')                                                                                                                                                                  \n",
        "                                                                                                                                                                                                            \n",
        "    if not instruction or not response:                                                                                                                                                                    \n",
        "        return {\"text\": \"\"}  # Skip empty samples                                                                                                                                                          \n",
        "                                                                                                                                                                                                            \n",
        "    text = f\"### Question:\\n{instruction}\\n\\n### Answer:\\n{response}\"                                                                                                                                      \n",
        "    return {\"text\": text}   \n",
        "\n",
        "# 데이터셋 변환\n",
        "formatted_dataset = dataset['train'].map(format_instruction, remove_columns=dataset['train'].column_names)\n",
        "print(f\"Formatted dataset size: {len(formatted_dataset)}\")\n",
        "print(f\"\\nSample formatted data:\")\n",
        "print(formatted_dataset[0]['text'][:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qwen2.5-0.5B 모델 로드\n",
        "\n",
        "4-bit quantization(QLoRA)을 적용하여 Qwen2.5-0.5B 모델을 로드하고 LoRA 어댑터를 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### WandB 초기화 및 SFTTrainer 설정\n",
        "\n",
        "WandB 실험을 초기화하고 SFTTrainer를 설정합니다. Sequence Packing을 활성화하여 학습 속도를 향상시킵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 학습 실행 및 모델 저장\n",
        "\n",
        "Qwen2.5-0.5B 모델 학습을 실행하고 최종 모델을 저장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LoRA 병합 및 Google Drive 저장 (0.5B)\n",
        "\n",
        "LoRA 어댑터를 base 모델에 병합하고 Google Drive에 저장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 메모리 정리\n",
        "\n",
        "다음 모델 학습을 위해 GPU 메모리를 해제합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 7912\n",
            "Validation samples: 880\n"
          ]
        }
      ],
      "source": [
        "# 학습/검증 데이터 분할 (90/10)\n",
        "split_dataset = formatted_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = split_dataset['train']\n",
        "eval_dataset = split_dataset['test']\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(eval_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qwen2.5-1.5B 모델 로드\n",
        "\n",
        "더 큰 1.5B 모델을 동일한 QLoRA 설정으로 로드합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### WandB 초기화 및 1.5B SFTTrainer 설정\n",
        "\n",
        "1.5B 모델용 WandB 실험을 초기화하고 더 큰 배치 크기로 SFTTrainer를 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5B 모델 학습 실행\n",
        "\n",
        "Qwen2.5-1.5B 모델 학습을 실행하고 저장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 모델 학습 설정\n",
        "\n",
        "### T4 GPU 환경에서의 최적화 전략:\n",
        "\n",
        "#### 메모리 최적화\n",
        "- **QLoRA** (4-bit quantization + LoRA): 메모리 효율적인 학습\n",
        "- **Gradient Checkpointing**: 메모리 사용량 감소\n",
        "\n",
        "#### 속도 최적화\n",
        "- **SDPA** (Scaled Dot Product Attention): T4에서 ~1.5x 빠른 attention\n",
        "  - Flash Attention 2는 Ampere (A100, A10) 이상만 지원\n",
        "  - T4 (Turing)에서는 자동으로 SDPA 사용\n",
        "- **torch.compile**: ~10-30% 전체 속도 향상\n",
        "- **Mixed Precision (fp16)**: 학습 속도 향상\n",
        "- **Sequence Packing**: 여러 샘플을 하나의 시퀀스에 패킹 → 2~3배 속도 향상\n",
        "- **Parallel Data Loading**: 4 workers로 병렬 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_model_and_tokenizer(model_id, use_qlora=True):\n",
        "    \"\"\"\n",
        "    모델과 토크나이저 설정\n",
        "    T4 GPU 환경에 최적화된 QLoRA 설정 적용\n",
        "\n",
        "    Attention 구현:\n",
        "    - Flash Attention 2: Ampere GPU 이상 (~2x 빠름)\n",
        "    - SDPA: T4 등 Turing GPU에서 사용 (~1.5x 빠름)\n",
        "    - eager: 기본 구현\n",
        "    \"\"\"\n",
        "    # Tokenizer 설정\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "    # padding token 설정 (없는 경우)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    if use_qlora:\n",
        "        # 4-bit quantization 설정\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,  # bfloat16 for better stability\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "        )\n",
        "\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "            attn_implementation=ATTN_IMPLEMENTATION,  # 자동 감지된 attention 사용\n",
        "        )\n",
        "\n",
        "        # QLoRA를 위한 모델 준비\n",
        "        model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
        "    else:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "            attn_implementation=ATTN_IMPLEMENTATION,\n",
        "        )\n",
        "\n",
        "    # LoRA 설정\n",
        "    lora_config = LoraConfig(\n",
        "        r=16,  # LoRA rank\n",
        "        lora_alpha=32,  # LoRA alpha\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                       \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_training_args(model_name, output_dir, fast_mode=False):\n",
        "    \"\"\"\n",
        "    T4 GPU에 최적화된 학습 인자 설정\n",
        "\n",
        "    Speed optimizations:\n",
        "    - dataloader_num_workers: 병렬 데이터 로딩\n",
        "    - dataloader_pin_memory: 빠른 CPU→GPU 전송\n",
        "    - torch_compile: ~10-30% 속도 향상\n",
        "    - 줄인 logging/eval 빈도: 오버헤드 감소\n",
        "    \"\"\"\n",
        "    args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        gradient_accumulation_steps=4,  # effective batch size = 16\n",
        "        gradient_checkpointing=True,\n",
        "        gradient_checkpointing_kwargs={\"use_reentrant\": False},  # 더 빠른 checkpointing\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        learning_rate=2e-4,\n",
        "        weight_decay=0.01,\n",
        "        fp16=True,\n",
        "        bf16=False,\n",
        "        max_grad_norm=0.3,\n",
        "        warmup_ratio=0.03,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "        logging_steps=25 if fast_mode else 10,  # 로깅 빈도 줄임\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=200 if fast_mode else 100,  # 저장 빈도 줄임\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=200 if fast_mode else 100,  # 평가 빈도 줄임\n",
        "        save_total_limit=2,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_loss\",\n",
        "        greater_is_better=False,\n",
        "        report_to=\"wandb\",\n",
        "        run_name=f\"{model_name}-math-sft\",\n",
        "        # Speed optimizations\n",
        "        dataloader_num_workers=0,  # 0=progress bar 표시 (Jupyter/Colab), 4=병렬 로딩(스크립트용)\n",
        "        dataloader_pin_memory=True,  # 빠른 메모리 전송\n",
        "        torch_compile=False,  # Colab/Triton 호환: True 시 KernelMetadata.cluster_dims 오류 발생\n",
        "        # dataloader_prefetch_factor=2,  # 데이터 프리페치\n",
        "    )\n",
        "    return args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Qwen2.5-0.5B 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: Qwen/Qwen2.5-0.5B\n",
            "Attention: sdpa\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3742b2e8582d465abb69b48acd2c1505",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cd3e2c0746540b98c3d75a9889ab68d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5df9b7e3d69d4713ae5a2df256f892de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b919f814321e45108edfcd2293c74085",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bd0977bc3214990b59b35a841a6febf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3983347bad604bdd846ff8cc909d1edc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42d7ba0717944d149187eb99c42d3642",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 8,798,208 || all params: 502,830,976 || trainable%: 1.7497\n"
          ]
        }
      ],
      "source": [
        "# Qwen2.5-0.5B 모델 설정 (QLoRA)\n",
        "MODEL_ID_05B = \"Qwen/Qwen2.5-0.5B\"\n",
        "OUTPUT_DIR_05B = \"./outputs/qwen2.5-0.5b-math-sft\"\n",
        "\n",
        "print(f\"Loading model: {MODEL_ID_05B}\")\n",
        "print(f\"Attention: {ATTN_IMPLEMENTATION}\")\n",
        "\n",
        "model_05b, tokenizer_05b = setup_model_and_tokenizer(MODEL_ID_05B, use_qlora=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260201_045123-o22sikov</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft/runs/o22sikov' target=\"_blank\">qwen2.5-0.5b-math-sft</a></strong> to <a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft' target=\"_blank\">https://wandb.ai/jungwoonshin/llm-math-reasoning-sft</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft/runs/o22sikov' target=\"_blank\">https://wandb.ai/jungwoonshin/llm-math-reasoning-sft/runs/o22sikov</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, packing. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:192: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68d61c37a92949a6a5c2dd03c29b0d91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0647a6ab599d4df28d4758090d3a24df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for Qwen2.5-0.5B...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:413: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(\n"
          ]
        }
      ],
      "source": [
        "# WandB 실행 초기화\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    entity=ENTITY,\n",
        "    name=\"qwen2.5-0.5b-math-sft\",\n",
        "    config={\n",
        "        \"model\": MODEL_ID_05B,\n",
        "        \"dataset\": \"qwedsacf/grade-school-math-instructions\",\n",
        "        \"method\": \"QLoRA\",\n",
        "        \"lora_r\": 16,\n",
        "        \"lora_alpha\": 32,\n",
        "        \"epochs\": 1,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 2e-4,\n",
        "    }\n",
        ")\n",
        "\n",
        "# 학습 인자 설정\n",
        "training_args_05b = get_training_args(\"qwen2.5-0.5b\", OUTPUT_DIR_05B)\n",
        "\n",
        "# Trainer 설정\n",
        "trainer_05b = SFTTrainer(\n",
        "    model=model_05b,\n",
        "    args=training_args_05b,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer_05b,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    packing=True,  # 여러 샘플을 한 시퀀스에 패킹 → 2~3배 속도 향상\n",
        ")\n",
        "\n",
        "print(\"Starting training for Qwen2.5-0.5B...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "cp: cannot stat './outputs/qwen2.5-0.5b-math-sft-merged': No such file or directory\n",
            "Models saved to Google Drive!\n"
          ]
        }
      ],
      "source": [
        "# Qwen2.5-0.5B 학습 실행\n",
        "trainer_05b.train()\n",
        "\n",
        "# 최종 모델 저장\n",
        "trainer_05b.save_model(f\"{OUTPUT_DIR_05B}/final\")\n",
        "tokenizer_05b.save_pretrained(f\"{OUTPUT_DIR_05B}/final\")\n",
        "\n",
        "print(f\"Model saved to {OUTPUT_DIR_05B}/final\")\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading base model: Qwen/Qwen2.5-0.5B\n",
            "Loading LoRA weights from: ./outputs/qwen2.5-0.5b-math-sft/final\n",
            "Merging weights...\n",
            "Saving merged model to: ./outputs/qwen2.5-0.5b-math-sft-merged\n",
            "Done!\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Models saved to Google Drive!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from peft import PeftModel\n",
        "import gc\n",
        "\n",
        "def merge_and_save_model(base_model_id, lora_path, output_path):\n",
        "    \"\"\"\n",
        "    LoRA 가중치를 base 모델에 병합하여 저장\n",
        "    \"\"\"\n",
        "    print(f\"Loading base model: {base_model_id}\")\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model_id,\n",
        "        dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    \n",
        "    print(f\"Loading LoRA weights from: {lora_path}\")\n",
        "    model = PeftModel.from_pretrained(base_model, lora_path)\n",
        "    \n",
        "    print(\"Merging weights...\")\n",
        "    merged_model = model.merge_and_unload()\n",
        "    \n",
        "    print(f\"Saving merged model to: {output_path}\")\n",
        "    merged_model.save_pretrained(output_path)\n",
        "    \n",
        "    # Tokenizer도 함께 저장\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
        "    tokenizer.save_pretrained(output_path)\n",
        "    \n",
        "    print(\"Done!\")\n",
        "    \n",
        "    # 메모리 정리\n",
        "    del base_model, model, merged_model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return output_path\n",
        "\n",
        "    # Qwen2.5-0.5B 모델 병합\n",
        "merged_05b_path = merge_and_save_model(\n",
        "    base_model_id=\"Qwen/Qwen2.5-0.5B\",\n",
        "    lora_path=f\"{OUTPUT_DIR_05B}/final\",\n",
        "    output_path=\"./outputs/qwen2.5-0.5b-math-sft-merged\"\n",
        ")\n",
        "\n",
        "\n",
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 저장 디렉토리 생성\n",
        "!mkdir -p /content/drive/MyDrive/llm-math-models/\n",
        "\n",
        "# 모델 복사\n",
        "!cp -r ./outputs/qwen2.5-0.5b-math-sft-merged /content/drive/MyDrive/llm-math-models/\n",
        "# !cp -r ./outputs/qwen2.5-1.5b-math-sft-merged /content/drive/MyDrive/llm-math-models/\n",
        "\n",
        "print(\"Models saved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33274"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 메모리 정리\n",
        "del model_05b, trainer_05b\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Qwen2.5-1.5B 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: Qwen/Qwen2.5-1.5B\n",
            "Attention: sdpa\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f42eb67a9c74bb6bc629a92fba65f1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5382401f64b443f0b1792acc5554fdfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe81b8bf72fc4335ba7578283aa44d76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e69de1471c64ebc9bf08b464823f6d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcbed2a106fd40fb89ccfcc7d0c64a9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17fd762ff3704c43865af5464ee399ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfeccb96ad3f4f6888beec6d488c21de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n"
          ]
        }
      ],
      "source": [
        "# Qwen2.5-1.5B 모델 설정 (QLoRA)\n",
        "MODEL_ID_15B = \"Qwen/Qwen2.5-1.5B\"\n",
        "OUTPUT_DIR_15B = \"./outputs/qwen2.5-1.5b-math-sft\"\n",
        "\n",
        "print(f\"Loading model: {MODEL_ID_15B}\")\n",
        "print(f\"Attention: {ATTN_IMPLEMENTATION}\")\n",
        "\n",
        "model_15b, tokenizer_15b = setup_model_and_tokenizer(MODEL_ID_15B, use_qlora=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260201_051407-rosg26zr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft/runs/rosg26zr' target=\"_blank\">qwen2.5-1.5b-math-sft-fast</a></strong> to <a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft' target=\"_blank\">https://wandb.ai/jungwoonshin/llm-math-reasoning-sft</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft/runs/rosg26zr' target=\"_blank\">https://wandb.ai/jungwoonshin/llm-math-reasoning-sft/runs/rosg26zr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, packing. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:192: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dda13824510246ff857d998f110dfc1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8784945ed1fd48b9bf4b8802a136d0d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for Qwen2.5-1.5B (optimized for speed)...\n",
            "Speed optimizations enabled:\n",
            "  - SDPA\n",
            "  - torch.compile\n",
            "  - Parallel data loading (4 workers)\n",
            "  - Sequence packing\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:413: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(\n"
          ]
        }
      ],
      "source": [
        "# WandB 실행 초기화\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    entity=ENTITY,\n",
        "    name=\"qwen2.5-1.5b-math-sft-fast\",\n",
        "    config={\n",
        "        \"model\": MODEL_ID_15B,\n",
        "        \"dataset\": \"qwedsacf/grade-school-math-instructions\",\n",
        "        \"method\": f\"QLoRA + {ATTN_IMPLEMENTATION}\",\n",
        "        \"lora_r\": 16,\n",
        "        \"lora_alpha\": 32,\n",
        "        \"epochs\": 3,\n",
        "        \"batch_size\": 32,  # effective batch size\n",
        "        \"learning_rate\": 2e-4,\n",
        "    }\n",
        ")\n",
        "\n",
        "# 학습 인자 설정 (1.5B 속도 최적화)\n",
        "training_args_15b = get_training_args(\"qwen2.5-1.5b\", OUTPUT_DIR_15B, fast_mode=True)\n",
        "training_args_15b.per_device_train_batch_size = 8  # 배치 크기 증가\n",
        "training_args_15b.gradient_accumulation_steps = 4  # effective batch size = 32\n",
        "training_args_15b.num_train_epochs = 3\n",
        "\n",
        "# Trainer 설정\n",
        "trainer_15b = SFTTrainer(\n",
        "    model=model_15b,\n",
        "    args=training_args_15b,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer_15b,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    packing=True,  # 여러 샘플을 한 시퀀스에 패킹 → 2~3배 속도 향상\n",
        ")\n",
        "\n",
        "print(\"Starting training for Qwen2.5-1.5B (optimized for speed)...\")\n",
        "print(f\"Speed optimizations enabled:\")\n",
        "print(f\"  - {ATTN_IMPLEMENTATION.upper()}\")\n",
        "print(f\"  - torch.compile\")\n",
        "print(f\"  - Parallel data loading (4 workers)\")\n",
        "print(f\"  - Sequence packing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [237/237 12:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.449900</td>\n",
              "      <td>0.800456</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to ./outputs/qwen2.5-1.5b-math-sft/final\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▄▅▆▇▇▁▂▃▃▄▅▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▄▅▆▇▇▁▂▃▃▄▅▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▆▆▆▄▆▇▁▃█▅▅▄▇█▅▄▃</td></tr><tr><td>train/learning_rate</td><td>██▇▆▄▃▂▁██▇▆▄▃▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▃▄▃▃▃▃▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.80046</td></tr><tr><td>eval/runtime</td><td>11.6877</td></tr><tr><td>eval/samples_per_second</td><td>23.443</td></tr><tr><td>eval/steps_per_second</td><td>5.904</td></tr><tr><td>total_flos</td><td>3.087692963040461e+16</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>237</td></tr><tr><td>train/grad_norm</td><td>0.30893</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4669</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">qwen2.5-1.5b-math-sft-fast</strong> at: <a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft/runs/rosg26zr' target=\"_blank\">https://wandb.ai/jungwoonshin/llm-math-reasoning-sft/runs/rosg26zr</a><br> View project at: <a href='https://wandb.ai/jungwoonshin/llm-math-reasoning-sft' target=\"_blank\">https://wandb.ai/jungwoonshin/llm-math-reasoning-sft</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260201_051407-rosg26zr/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Qwen2.5-1.5B 학습 실행\n",
        "trainer_15b.train()\n",
        "\n",
        "# 최종 모델 저장\n",
        "trainer_15b.save_model(f\"{OUTPUT_DIR_15B}/final\")\n",
        "tokenizer_15b.save_pretrained(f\"{OUTPUT_DIR_15B}/final\")\n",
        "\n",
        "print(f\"Model saved to {OUTPUT_DIR_15B}/final\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3042"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 메모리 정리\n",
        "del model_15b, trainer_15b\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. LoRA 가중치를 Base 모델에 병합\n",
        "\n",
        "평가를 위해 LoRA 가중치를 base 모델에 병합하여 완전한 모델로 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "def merge_and_save_model(base_model_id, lora_path, output_path):\n",
        "    \"\"\"\n",
        "    LoRA 가중치를 base 모델에 병합하여 저장\n",
        "    \"\"\"\n",
        "    print(f\"Loading base model: {base_model_id}\")\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    \n",
        "    print(f\"Loading LoRA weights from: {lora_path}\")\n",
        "    model = PeftModel.from_pretrained(base_model, lora_path)\n",
        "    \n",
        "    print(\"Merging weights...\")\n",
        "    merged_model = model.merge_and_unload()\n",
        "    \n",
        "    print(f\"Saving merged model to: {output_path}\")\n",
        "    merged_model.save_pretrained(output_path)\n",
        "    \n",
        "    # Tokenizer도 함께 저장\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
        "    tokenizer.save_pretrained(output_path)\n",
        "    \n",
        "    print(\"Done!\")\n",
        "    \n",
        "    # 메모리 정리\n",
        "    del base_model, model, merged_model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading base model: Qwen/Qwen2.5-0.5B\n",
            "Loading LoRA weights from: ./outputs/qwen2.5-0.5b-math-sft/final\n",
            "Merging weights...\n",
            "Saving merged model to: ./outputs/qwen2.5-0.5b-math-sft-merged\n",
            "Done!\n",
            "Loading base model: Qwen/Qwen2.5-1.5B\n",
            "Loading LoRA weights from: ./outputs/qwen2.5-1.5b-math-sft/final\n",
            "Merging weights...\n",
            "Saving merged model to: ./outputs/qwen2.5-1.5b-math-sft-merged\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Qwen2.5-0.5B 모델 병합\n",
        "merged_05b_path = merge_and_save_model(\n",
        "    base_model_id=\"Qwen/Qwen2.5-0.5B\",\n",
        "    lora_path=f\"{OUTPUT_DIR_05B}/final\",\n",
        "    output_path=\"./outputs/qwen2.5-0.5b-math-sft-merged\"\n",
        ")\n",
        "\n",
        "# Qwen2.5-1.5B 모델 병합\n",
        "merged_15b_path = merge_and_save_model(\n",
        "    base_model_id=\"Qwen/Qwen2.5-1.5B\",\n",
        "    lora_path=f\"{OUTPUT_DIR_15B}/final\",\n",
        "    output_path=\"./outputs/qwen2.5-1.5b-math-sft-merged\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading base model: Qwen/Qwen2.5-1.5B\n",
            "Loading LoRA weights from: ./outputs/qwen2.5-1.5b-math-sft/final\n",
            "Merging weights...\n",
            "Saving merged model to: ./outputs/qwen2.5-1.5b-math-sft-merged\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Qwen2.5-1.5B 모델 병합\n",
        "merged_15b_path = merge_and_save_model(\n",
        "    base_model_id=\"Qwen/Qwen2.5-1.5B\",\n",
        "    lora_path=f\"{OUTPUT_DIR_15B}/final\",\n",
        "    output_path=\"./outputs/qwen2.5-1.5b-math-sft-merged\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 학습된 모델 Google Drive 저장 (선택사항)\n",
        "\n",
        "Colab 런타임이 종료되면 모델이 삭제되므로, Google Drive에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Models saved to Google Drive!\n"
          ]
        }
      ],
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 저장 디렉토리 생성\n",
        "!mkdir -p /content/drive/MyDrive/llm-math-models/\n",
        "\n",
        "# 모델 복사\n",
        "# !cp -r ./outputs/qwen2.5-0.5b-math-sft-merged /content/drive/MyDrive/llm-math-models/\n",
        "!cp -r ./outputs/qwen2.5-1.5b-math-sft-merged /content/drive/MyDrive/llm-math-models/\n",
        "\n",
        "print(\"Models saved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 학습 완료\n",
        "\n",
        "다음 단계:\n",
        "1. `02_evaluation.ipynb`를 실행하여 모델 평가 수행\n",
        "2. WandB 대시보드에서 학습 과정 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['INSTRUCTION', 'RESPONSE', 'SOURCE']\n",
            "{'INSTRUCTION': 'This math problem has got me stumped: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\nCan you show me the way?', 'RESPONSE': 'Natalia sold 48/2 = 24 clips in May.\\nNatalia sold 48+24 = 72 clips altogether in April and May.', 'SOURCE': 'grade-school-math'}\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"qwedsacf/grade-school-math-instructions\")\n",
        "print(dataset['train'].column_names)  # 실제 필드명 확인\n",
        "print(dataset['train'][0])  # 샘플 확인"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
