{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM 수리추론 능력 평가\n",
    "\n",
    "## 평가 대상 모델\n",
    "1. **Base 모델 (학습 전)**: Qwen2.5-0.5B, Qwen2.5-1.5B\n",
    "2. **SFT 학습 모델**: Qwen2.5-0.5B-math-sft, Qwen2.5-1.5B-math-sft\n",
    "3. **SFT Improved (MC objective)**: Qwen2.5-0.5B-math-SFT-Improved (03_sft_training_improved.ipynb)\n",
    "4. **Instruct 모델 (비교용)**: Qwen2.5-0.5B-Instruct, Qwen2.5-1.5B-Instruct\n",
    "\n",
    "## 평가 방법\n",
    "- **평가 프레임워크**: lm-evaluation-harness\n",
    "- **평가 태스크**: mathqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정\n",
    "\n",
    "### 의존성 버전\n",
    "| 패키지 | 버전 |\n",
    "|--------|------|\n",
    "| torch | 2.4.0+cu118 |\n",
    "| transformers | 4.44.2 |\n",
    "| accelerate | 0.33.0 |\n",
    "| lm-eval | 0.4.3 |\n",
    "| datasets | 2.21.0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PyTorch 설치 (CUDA 11.8)\n",
    "# !pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 핵심 라이브러리 설치 (버전 명시)\n",
    "# !pip install transformers==4.44.2\n",
    "# !pip install datasets==2.21.0\n",
    "# !pip install accelerate==0.33.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lm-eval==0.4.3 in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (1.12.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (2.21.0)\n",
      "Requirement already satisfied: jsonlines in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (2.14.1)\n",
      "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (0.12.0)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (3.0.1)\n",
      "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (1.2.1)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (1.6.1)\n",
      "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (2.1.0)\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (2.9.0+cu126)\n",
      "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (0.0.11)\n",
      "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (4.57.6)\n",
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (0.25.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (0.3.8)\n",
      "Requirement already satisfied: word2number in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (1.1)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from lm-eval==0.4.3) (10.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->lm-eval==0.4.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->lm-eval==0.4.3) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->lm-eval==0.4.3) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->lm-eval==0.4.3) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->lm-eval==0.4.3) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->lm-eval==0.4.3) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->lm-eval==0.4.3) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->lm-eval==0.4.3) (18.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->lm-eval==0.4.3) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->lm-eval==0.4.3) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->lm-eval==0.4.3) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->lm-eval==0.4.3) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->lm-eval==0.4.3) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.3) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->lm-eval==0.4.3) (3.13.3)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.3) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.3) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.3) (1.17.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.3) (3.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.3) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.3) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.3) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.3) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.3) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.3) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.3) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->lm-eval==0.4.3) (3.5.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.1->lm-eval==0.4.3) (0.22.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines->lm-eval==0.4.3) (25.4.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval==0.4.3) (1.1.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval==0.4.3) (1.1.4)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval==0.4.3) (3.3.1)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval==0.4.3) (1.3.4)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval==0.4.3) (0.1.7)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.3) (1.3.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.3) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.3) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.3) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.3) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.3) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval==0.4.3) (1.22.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0->lm-eval==0.4.3) (1.2.0)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval==0.4.3) (5.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.3) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.3) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.3) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.3) (2026.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->lm-eval==0.4.3) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.12/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.3) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->lm-eval==0.4.3) (3.0.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval==0.4.3) (8.3.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.16.0->lm-eval==0.4.3) (2025.3)\n",
      "Requirement already satisfied: datasets<4.0,>=2.16.0 in /usr/local/lib/python3.12/dist-packages (2.21.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<4.0,>=2.16.0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0,>=2.16.0) (6.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<4.0,>=2.16.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<4.0,>=2.16.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<4.0,>=2.16.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<4.0,>=2.16.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<4.0,>=2.16.0) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<4.0,>=2.16.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<4.0,>=2.16.0) (1.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets<4.0,>=2.16.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets<4.0,>=2.16.0) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0,>=2.16.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0,>=2.16.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0,>=2.16.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0,>=2.16.0) (2026.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0,>=2.16.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0,>=2.16.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0,>=2.16.0) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0,>=2.16.0) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# lm-evaluation-harness 설치 (특정 버전 태그 사용)\n",
    "!pip install lm-eval==0.4.3\n",
    "\n",
    "# mathqa는 allenai/math_qa 로딩 스크립트 사용 → datasets 4.0+에서 미지원\n",
    "# datasets<4.0으로 다운그레이드하여 mathqa 평가 가능하게 함\n",
    "!pip install \"datasets>=2.16.0,<4.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.9.0+cu126\n",
      "Name: transformers\n",
      "Version: 4.57.6\n",
      "Name: datasets\n",
      "Version: 2.21.0\n",
      "Name: accelerate\n",
      "Version: 1.12.0\n",
      "Name: lm_eval\n",
      "Version: 0.4.3\n"
     ]
    }
   ],
   "source": [
    "# 설치된 버전 확인\n",
    "!pip show torch transformers datasets accelerate lm-eval | grep -E \"^(Name|Version)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 임포트 및 GPU 확인\n",
    "\n",
    "평가에 필요한 라이브러리를 임포트하고 GPU 환경을 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 함수 정의\n",
    "\n",
    "lm-evaluation-harness를 사용하여 모델을 mathqa 태스크로 평가하는 함수입니다. 모델 로드, 평가 실행, 결과 저장, 메모리 정리를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA Version: 12.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from datetime import datetime\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "import lm_eval\n",
    "\n",
    "# GPU 확인\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장용 딕셔너리\n",
    "all_results = {}\n",
    "\n",
    "def evaluate_model(model_id_or_path, model_name, device=\"cuda\", is_local=False):\n",
    "    \"\"\"\n",
    "    모델을 mathqa 태스크로 평가\n",
    "    \n",
    "    Args:\n",
    "        model_id_or_path: HuggingFace 모델 ID 또는 로컬 경로\n",
    "        model_name: 결과 저장용 모델 이름\n",
    "        device: 사용할 디바이스\n",
    "        is_local: 로컬 모델 여부\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {model_name}\")\n",
    "    print(f\"Model path: {model_id_or_path}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 모델 및 토크나이저 로드\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id_or_path,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id_or_path,\n",
    "        trust_remote_code=True,\n",
    "        use_fast=False if is_local else True,  # 로컬 SFT: tokenizer.json 버전 호환 오류 회피\n",
    "    )\n",
    "    \n",
    "    # HFLM 래퍼 생성\n",
    "    lm = HFLM(\n",
    "        pretrained=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=1024,\n",
    "        batch_size='auto',\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    # 평가 실행\n",
    "    results = lm_eval.simple_evaluate(\n",
    "        model=lm,\n",
    "        tasks=[\"mathqa\"],\n",
    "        task_manager=lm_eval.tasks.TaskManager(),\n",
    "    )\n",
    "    \n",
    "    # 결과 추출\n",
    "    accuracy = results['results']['mathqa']['acc,none']\n",
    "    acc_stderr = results['results']['mathqa'].get('acc_stderr,none', 0)\n",
    "    \n",
    "    # 결과 저장\n",
    "    all_results[model_name] = {\n",
    "        'model_path': model_id_or_path,\n",
    "        'accuracy': accuracy,\n",
    "        'acc_stderr': acc_stderr,\n",
    "        'full_results': results['results']['mathqa'],\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f} (+/- {acc_stderr:.4f})\")\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del model, tokenizer, lm\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    return accuracy, acc_stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base 모델 평가 (학습 전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: Qwen2.5-0.5B (Base)\n",
      "Model path: Qwen/Qwen2.5-0.5B\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c37532054ee468cb106f266126c5dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d67a36158ef40f1bafc32e678403889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148479a1ceb34fb3974c40f6bc577df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5759f3bae44b4187ae8abfe8cf47ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/29837 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0ea22455654e2680a3f35b20ee8d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14dd5a9235af4269a614fb5f7a0366c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2078.64it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests:   0%|          | 1/14925 [00:01<7:07:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined largest batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [00:12<00:00, 1225.00it/s]\n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-0.5B (Base) Results:\n",
      "  Accuracy: 0.2874 (+/- 0.0083)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28743718592964823, 0.008284830813404314)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-0.5B Base 모델 평가\n",
    "evaluate_model(\n",
    "    model_id_or_path=\"Qwen/Qwen2.5-0.5B\",\n",
    "    model_name=\"Qwen2.5-0.5B (Base)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: Qwen2.5-1.5B (Base)\n",
      "Model path: Qwen/Qwen2.5-1.5B\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d9d53a78714100a88d20de95ef646d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4fb3ec4cd94db4af223fcf36201221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0299669b4ff24df2b302bf692251f651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6c85b16cd144e69dee4d15d0f9db2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e7e375d8b84ea29f4a3f9d9ee11357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852d068961744de9a76d5a3ec9e197f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24170b0a360d4628a6b397900edc2e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n",
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2061.86it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n",
      "Determined largest batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [00:18<00:00, 787.72it/s] \n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 1536)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 1536)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-1.5B (Base) Results:\n",
      "  Accuracy: 0.3461 (+/- 0.0087)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.34606365159128977, 0.008708559482308245)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-1.5B Base 모델 평가\n",
    "evaluate_model(\n",
    "    model_id_or_path=\"Qwen/Qwen2.5-1.5B\",\n",
    "    model_name=\"Qwen2.5-1.5B (Base)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instruct 모델 평가 (비교용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: Qwen2.5-0.5B-Instruct\n",
      "Model path: Qwen/Qwen2.5-0.5B-Instruct\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e957721d93554e83b1c9e810a079c425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f83c67accf4887a599d816af097abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0b3bcdbd154266aafe56c554da042c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8042df1f404916a89a92efa811509f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0cf8c96b7d4e3182d89bb909227e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c88acab36f647eaa86ad078cadb90e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74420c40000432cae237e3f894ee913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n",
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2037.83it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests:   0%|          | 1/14925 [00:01<5:25:32,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined largest batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [00:11<00:00, 1245.47it/s]\n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-0.5B-Instruct Results:\n",
      "  Accuracy: 0.2901 (+/- 0.0083)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2901172529313233, 0.008307697593432424)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-0.5B-Instruct 모델 평가\n",
    "evaluate_model(\n",
    "    model_id_or_path=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    model_name=\"Qwen2.5-0.5B-Instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Drive 마운트 및 모델 경로 설정\n",
    "\n",
    "Google Drive를 마운트하고 학습된 SFT 모델들의 경로를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: Qwen2.5-1.5B-Instruct\n",
      "Model path: Qwen/Qwen2.5-1.5B-Instruct\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888cc2ca843349028fc0e4490b3abfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f854e7c8d773422690d539b31f791005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba770d9410e404aaccddfc05f21b147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41d6630d3ec42dfa2a5efa74935c064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aca76a48d3b417d8c162b8bdb62a091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba26ef171384efaafda434a7c24a305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e324c983dff41899bb0c1c9913d9403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n",
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2065.58it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n",
      "Determined largest batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [00:18<00:00, 788.21it/s] \n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 1536)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 1536)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-1.5B-Instruct Results:\n",
      "  Accuracy: 0.3374 (+/- 0.0087)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3373534338358459, 0.008655340029744593)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-1.5B-Instruct 모델 평가\n",
    "evaluate_model(\n",
    "    model_id_or_path=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    model_name=\"Qwen2.5-1.5B-Instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SFT 학습 모델 평가\n",
    "\n",
    "학습된 모델이 저장된 경로를 지정하세요. Google Drive에 저장한 경우 해당 경로를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Google Drive 마운트 (필요한 경우)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 학습된 모델 경로 설정\n",
    "SFT_MODEL_05B_PATH = \"/content/drive/MyDrive/llm-math-models/qwen2.5-0.5b-math-sft-merged\"\n",
    "SFT_MODEL_15B_PATH = \"/content/drive/MyDrive/llm-math-models/qwen2.5-1.5b-math-sft-merged\"\n",
    "\n",
    "# 03_sft_training_improved.ipynb에서 학습 후 Drive에 업로드한 모델\n",
    "SFT_IMPROVED_MODEL_05B_PATH = \"/content/drive/MyDrive/llm-math-models/qwen2.5-0.5b-math-sft-improved-mc\"\n",
    "SFT_IMPROVED_MODEL_15B_PATH = \"/content/drive/MyDrive/llm-math-models/qwen2.5-1.5b-math-sft-improved-mc\"\n",
    "\n",
    "# 또는 로컬 경로 사용 (같은 세션에서 학습한 경우)\n",
    "# SFT_MODEL_05B_PATH = \"./outputs/qwen2.5-0.5b-math-sft-merged\"\n",
    "# SFT_MODEL_15B_PATH = \"./outputs/qwen2.5-1.5b-math-sft-merged\"\n",
    "# SFT_IMPROVED_MODEL_05B_PATH = \"./outputs/03_sft_improved_mc\"\n",
    "# SFT_IMPROVED_MODEL_15B_PATH = \"./outputs/03_sft_improved_mc_1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: Qwen2.5-0.5B-math-SFT\n",
      "Model path: /content/drive/MyDrive/llm-math-models/qwen2.5-0.5b-math-sft-merged\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n",
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2059.85it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests:   0%|          | 1/14925 [00:01<5:28:19,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined largest batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [00:11<00:00, 1268.00it/s]\n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-0.5B-math-SFT Results:\n",
      "  Accuracy: 0.2884 (+/- 0.0083)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2884422110552764, 0.00829344725702771)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-0.5B SFT 모델 평가\n",
    "evaluate_model(\n",
    "    model_id_or_path=SFT_MODEL_05B_PATH,\n",
    "    model_name=\"Qwen2.5-0.5B-math-SFT\",\n",
    "    is_local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: Qwen2.5-1.5B-math-SFT\n",
      "Model path: /content/drive/MyDrive/llm-math-models/qwen2.5-1.5b-math-sft-merged\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n",
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2042.88it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n",
      "Determined largest batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [00:18<00:00, 788.40it/s] \n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 1536)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 1536)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-1.5B-math-SFT Results:\n",
      "  Accuracy: 0.2978 (+/- 0.0084)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.297822445561139, 0.008371490230938748)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-1.5B SFT 모델 평가\n",
    "evaluate_model(\n",
    "    model_id_or_path=SFT_MODEL_15B_PATH,\n",
    "    model_name=\"Qwen2.5-1.5B-math-SFT\",\n",
    "    is_local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: 04_mathqa_gsm_combined\n",
      "Model path: /content/drive/MyDrive/outputs/04_mathqa_gsm_combined\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n",
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2064.90it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests:   0%|          | 1/14925 [00:08<33:36:17,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined largest batch size: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [01:04<00:00, 232.59it/s]\n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (k_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (v_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (o_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (up_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (down_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=4864, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4864, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (k_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (v_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (o_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (up_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (down_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=4864, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4864, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "04_mathqa_gsm_combined Results:\n",
      "  Accuracy: 0.3363 (+/- 0.0086)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.33634840871021776, 0.008648989090541835)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-0.5B SFT Improved (MC) 모델 평가 (03_sft_training_improved.ipynb)\n",
    "evaluate_model(\n",
    "    model_id_or_path=\"/content/drive/MyDrive/outputs/04_mathqa_gsm_combined\",\n",
    "    model_name=\"04_mathqa_gsm_combined\",\n",
    "    is_local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 DataFrame 생성 및 정렬\n",
    "\n",
    "모든 평가 결과를 pandas DataFrame으로 변환하고 모델 순서대로 정렬합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 향상 분석\n",
    "\n",
    "Base 모델 대비 SFT 모델의 성능 향상을 계산합니다. 절대/상대 향상률과 Instruct 모델과의 비교를 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 시각화\n",
    "\n",
    "0.5B와 1.5B 모델 결과를 막대 그래프로 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: 04_mathqa_only\n",
      "Model path: /content/drive/MyDrive/outputs/04_mathqa_only\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n",
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2033.88it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests:   0%|          | 1/14925 [00:04<20:20:12,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined largest batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [00:42<00:00, 350.48it/s]\n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (k_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (v_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (o_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (up_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (down_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=4864, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4864, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (k_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (v_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (o_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (up_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (down_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=4864, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4864, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "04_mathqa_only Results:\n",
      "  Accuracy: 0.3558 (+/- 0.0088)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.35577889447236183, 0.008764116776307925)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-0.5B SFT Improved (MC) 모델 평가 (03_sft_training_improved.ipynb)\n",
    "evaluate_model(\n",
    "    model_id_or_path=\"/content/drive/MyDrive/outputs/04_mathqa_only\",\n",
    "    model_name=\"04_mathqa_only\",\n",
    "    is_local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating: Qwen2.5-0.5B-math-SFT-Improved-mc\n",
      "Model path: /content/drive/MyDrive/llm-math-models/qwen2.5-0.5b-math-sft-improved-mc\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from /content/drive/MyDrive/llm-math-models/qwen2.5-0.5b-math-sft-improved-mc led to missing keys in the model: model.layers.0.self_attn.q_proj.lora_A.default.weight, model.layers.0.self_attn.q_proj.lora_B.default.weight, model.layers.0.self_attn.k_proj.lora_A.default.weight, model.layers.0.self_attn.k_proj.lora_B.default.weight, model.layers.0.self_attn.v_proj.lora_A.default.weight, model.layers.0.self_attn.v_proj.lora_B.default.weight, model.layers.0.self_attn.o_proj.lora_A.default.weight, model.layers.0.self_attn.o_proj.lora_B.default.weight, model.layers.0.mlp.gate_proj.lora_A.default.weight, model.layers.0.mlp.gate_proj.lora_B.default.weight, model.layers.0.mlp.up_proj.lora_A.default.weight, model.layers.0.mlp.up_proj.lora_B.default.weight, model.layers.0.mlp.down_proj.lora_A.default.weight, model.layers.0.mlp.down_proj.lora_B.default.weight, model.layers.1.self_attn.q_proj.lora_A.default.weight, model.layers.1.self_attn.q_proj.lora_B.default.weight, model.layers.1.self_attn.k_proj.lora_A.default.weight, model.layers.1.self_attn.k_proj.lora_B.default.weight, model.layers.1.self_attn.v_proj.lora_A.default.weight, model.layers.1.self_attn.v_proj.lora_B.default.weight, model.layers.1.self_attn.o_proj.lora_A.default.weight, model.layers.1.self_attn.o_proj.lora_B.default.weight, model.layers.1.mlp.gate_proj.lora_A.default.weight, model.layers.1.mlp.gate_proj.lora_B.default.weight, model.layers.1.mlp.up_proj.lora_A.default.weight, model.layers.1.mlp.up_proj.lora_B.default.weight, model.layers.1.mlp.down_proj.lora_A.default.weight, model.layers.1.mlp.down_proj.lora_B.default.weight, model.layers.2.self_attn.q_proj.lora_A.default.weight, model.layers.2.self_attn.q_proj.lora_B.default.weight, model.layers.2.self_attn.k_proj.lora_A.default.weight, model.layers.2.self_attn.k_proj.lora_B.default.weight, model.layers.2.self_attn.v_proj.lora_A.default.weight, model.layers.2.self_attn.v_proj.lora_B.default.weight, model.layers.2.self_attn.o_proj.lora_A.default.weight, model.layers.2.self_attn.o_proj.lora_B.default.weight, model.layers.2.mlp.gate_proj.lora_A.default.weight, model.layers.2.mlp.gate_proj.lora_B.default.weight, model.layers.2.mlp.up_proj.lora_A.default.weight, model.layers.2.mlp.up_proj.lora_B.default.weight, model.layers.2.mlp.down_proj.lora_A.default.weight, model.layers.2.mlp.down_proj.lora_B.default.weight, model.layers.3.self_attn.q_proj.lora_A.default.weight, model.layers.3.self_attn.q_proj.lora_B.default.weight, model.layers.3.self_attn.k_proj.lora_A.default.weight, model.layers.3.self_attn.k_proj.lora_B.default.weight, model.layers.3.self_attn.v_proj.lora_A.default.weight, model.layers.3.self_attn.v_proj.lora_B.default.weight, model.layers.3.self_attn.o_proj.lora_A.default.weight, model.layers.3.self_attn.o_proj.lora_B.default.weight, model.layers.3.mlp.gate_proj.lora_A.default.weight, model.layers.3.mlp.gate_proj.lora_B.default.weight, model.layers.3.mlp.up_proj.lora_A.default.weight, model.layers.3.mlp.up_proj.lora_B.default.weight, model.layers.3.mlp.down_proj.lora_A.default.weight, model.layers.3.mlp.down_proj.lora_B.default.weight, model.layers.4.self_attn.q_proj.lora_A.default.weight, model.layers.4.self_attn.q_proj.lora_B.default.weight, model.layers.4.self_attn.k_proj.lora_A.default.weight, model.layers.4.self_attn.k_proj.lora_B.default.weight, model.layers.4.self_attn.v_proj.lora_A.default.weight, model.layers.4.self_attn.v_proj.lora_B.default.weight, model.layers.4.self_attn.o_proj.lora_A.default.weight, model.layers.4.self_attn.o_proj.lora_B.default.weight, model.layers.4.mlp.gate_proj.lora_A.default.weight, model.layers.4.mlp.gate_proj.lora_B.default.weight, model.layers.4.mlp.up_proj.lora_A.default.weight, model.layers.4.mlp.up_proj.lora_B.default.weight, model.layers.4.mlp.down_proj.lora_A.default.weight, model.layers.4.mlp.down_proj.lora_B.default.weight, model.layers.5.self_attn.q_proj.lora_A.default.weight, model.layers.5.self_attn.q_proj.lora_B.default.weight, model.layers.5.self_attn.k_proj.lora_A.default.weight, model.layers.5.self_attn.k_proj.lora_B.default.weight, model.layers.5.self_attn.v_proj.lora_A.default.weight, model.layers.5.self_attn.v_proj.lora_B.default.weight, model.layers.5.self_attn.o_proj.lora_A.default.weight, model.layers.5.self_attn.o_proj.lora_B.default.weight, model.layers.5.mlp.gate_proj.lora_A.default.weight, model.layers.5.mlp.gate_proj.lora_B.default.weight, model.layers.5.mlp.up_proj.lora_A.default.weight, model.layers.5.mlp.up_proj.lora_B.default.weight, model.layers.5.mlp.down_proj.lora_A.default.weight, model.layers.5.mlp.down_proj.lora_B.default.weight, model.layers.6.self_attn.q_proj.lora_A.default.weight, model.layers.6.self_attn.q_proj.lora_B.default.weight, model.layers.6.self_attn.k_proj.lora_A.default.weight, model.layers.6.self_attn.k_proj.lora_B.default.weight, model.layers.6.self_attn.v_proj.lora_A.default.weight, model.layers.6.self_attn.v_proj.lora_B.default.weight, model.layers.6.self_attn.o_proj.lora_A.default.weight, model.layers.6.self_attn.o_proj.lora_B.default.weight, model.layers.6.mlp.gate_proj.lora_A.default.weight, model.layers.6.mlp.gate_proj.lora_B.default.weight, model.layers.6.mlp.up_proj.lora_A.default.weight, model.layers.6.mlp.up_proj.lora_B.default.weight, model.layers.6.mlp.down_proj.lora_A.default.weight, model.layers.6.mlp.down_proj.lora_B.default.weight, model.layers.7.self_attn.q_proj.lora_A.default.weight, model.layers.7.self_attn.q_proj.lora_B.default.weight, model.layers.7.self_attn.k_proj.lora_A.default.weight, model.layers.7.self_attn.k_proj.lora_B.default.weight, model.layers.7.self_attn.v_proj.lora_A.default.weight, model.layers.7.self_attn.v_proj.lora_B.default.weight, model.layers.7.self_attn.o_proj.lora_A.default.weight, model.layers.7.self_attn.o_proj.lora_B.default.weight, model.layers.7.mlp.gate_proj.lora_A.default.weight, model.layers.7.mlp.gate_proj.lora_B.default.weight, model.layers.7.mlp.up_proj.lora_A.default.weight, model.layers.7.mlp.up_proj.lora_B.default.weight, model.layers.7.mlp.down_proj.lora_A.default.weight, model.layers.7.mlp.down_proj.lora_B.default.weight, model.layers.8.self_attn.q_proj.lora_A.default.weight, model.layers.8.self_attn.q_proj.lora_B.default.weight, model.layers.8.self_attn.k_proj.lora_A.default.weight, model.layers.8.self_attn.k_proj.lora_B.default.weight, model.layers.8.self_attn.v_proj.lora_A.default.weight, model.layers.8.self_attn.v_proj.lora_B.default.weight, model.layers.8.self_attn.o_proj.lora_A.default.weight, model.layers.8.self_attn.o_proj.lora_B.default.weight, model.layers.8.mlp.gate_proj.lora_A.default.weight, model.layers.8.mlp.gate_proj.lora_B.default.weight, model.layers.8.mlp.up_proj.lora_A.default.weight, model.layers.8.mlp.up_proj.lora_B.default.weight, model.layers.8.mlp.down_proj.lora_A.default.weight, model.layers.8.mlp.down_proj.lora_B.default.weight, model.layers.9.self_attn.q_proj.lora_A.default.weight, model.layers.9.self_attn.q_proj.lora_B.default.weight, model.layers.9.self_attn.k_proj.lora_A.default.weight, model.layers.9.self_attn.k_proj.lora_B.default.weight, model.layers.9.self_attn.v_proj.lora_A.default.weight, model.layers.9.self_attn.v_proj.lora_B.default.weight, model.layers.9.self_attn.o_proj.lora_A.default.weight, model.layers.9.self_attn.o_proj.lora_B.default.weight, model.layers.9.mlp.gate_proj.lora_A.default.weight, model.layers.9.mlp.gate_proj.lora_B.default.weight, model.layers.9.mlp.up_proj.lora_A.default.weight, model.layers.9.mlp.up_proj.lora_B.default.weight, model.layers.9.mlp.down_proj.lora_A.default.weight, model.layers.9.mlp.down_proj.lora_B.default.weight, model.layers.10.self_attn.q_proj.lora_A.default.weight, model.layers.10.self_attn.q_proj.lora_B.default.weight, model.layers.10.self_attn.k_proj.lora_A.default.weight, model.layers.10.self_attn.k_proj.lora_B.default.weight, model.layers.10.self_attn.v_proj.lora_A.default.weight, model.layers.10.self_attn.v_proj.lora_B.default.weight, model.layers.10.self_attn.o_proj.lora_A.default.weight, model.layers.10.self_attn.o_proj.lora_B.default.weight, model.layers.10.mlp.gate_proj.lora_A.default.weight, model.layers.10.mlp.gate_proj.lora_B.default.weight, model.layers.10.mlp.up_proj.lora_A.default.weight, model.layers.10.mlp.up_proj.lora_B.default.weight, model.layers.10.mlp.down_proj.lora_A.default.weight, model.layers.10.mlp.down_proj.lora_B.default.weight, model.layers.11.self_attn.q_proj.lora_A.default.weight, model.layers.11.self_attn.q_proj.lora_B.default.weight, model.layers.11.self_attn.k_proj.lora_A.default.weight, model.layers.11.self_attn.k_proj.lora_B.default.weight, model.layers.11.self_attn.v_proj.lora_A.default.weight, model.layers.11.self_attn.v_proj.lora_B.default.weight, model.layers.11.self_attn.o_proj.lora_A.default.weight, model.layers.11.self_attn.o_proj.lora_B.default.weight, model.layers.11.mlp.gate_proj.lora_A.default.weight, model.layers.11.mlp.gate_proj.lora_B.default.weight, model.layers.11.mlp.up_proj.lora_A.default.weight, model.layers.11.mlp.up_proj.lora_B.default.weight, model.layers.11.mlp.down_proj.lora_A.default.weight, model.layers.11.mlp.down_proj.lora_B.default.weight, model.layers.12.self_attn.q_proj.lora_A.default.weight, model.layers.12.self_attn.q_proj.lora_B.default.weight, model.layers.12.self_attn.k_proj.lora_A.default.weight, model.layers.12.self_attn.k_proj.lora_B.default.weight, model.layers.12.self_attn.v_proj.lora_A.default.weight, model.layers.12.self_attn.v_proj.lora_B.default.weight, model.layers.12.self_attn.o_proj.lora_A.default.weight, model.layers.12.self_attn.o_proj.lora_B.default.weight, model.layers.12.mlp.gate_proj.lora_A.default.weight, model.layers.12.mlp.gate_proj.lora_B.default.weight, model.layers.12.mlp.up_proj.lora_A.default.weight, model.layers.12.mlp.up_proj.lora_B.default.weight, model.layers.12.mlp.down_proj.lora_A.default.weight, model.layers.12.mlp.down_proj.lora_B.default.weight, model.layers.13.self_attn.q_proj.lora_A.default.weight, model.layers.13.self_attn.q_proj.lora_B.default.weight, model.layers.13.self_attn.k_proj.lora_A.default.weight, model.layers.13.self_attn.k_proj.lora_B.default.weight, model.layers.13.self_attn.v_proj.lora_A.default.weight, model.layers.13.self_attn.v_proj.lora_B.default.weight, model.layers.13.self_attn.o_proj.lora_A.default.weight, model.layers.13.self_attn.o_proj.lora_B.default.weight, model.layers.13.mlp.gate_proj.lora_A.default.weight, model.layers.13.mlp.gate_proj.lora_B.default.weight, model.layers.13.mlp.up_proj.lora_A.default.weight, model.layers.13.mlp.up_proj.lora_B.default.weight, model.layers.13.mlp.down_proj.lora_A.default.weight, model.layers.13.mlp.down_proj.lora_B.default.weight, model.layers.14.self_attn.q_proj.lora_A.default.weight, model.layers.14.self_attn.q_proj.lora_B.default.weight, model.layers.14.self_attn.k_proj.lora_A.default.weight, model.layers.14.self_attn.k_proj.lora_B.default.weight, model.layers.14.self_attn.v_proj.lora_A.default.weight, model.layers.14.self_attn.v_proj.lora_B.default.weight, model.layers.14.self_attn.o_proj.lora_A.default.weight, model.layers.14.self_attn.o_proj.lora_B.default.weight, model.layers.14.mlp.gate_proj.lora_A.default.weight, model.layers.14.mlp.gate_proj.lora_B.default.weight, model.layers.14.mlp.up_proj.lora_A.default.weight, model.layers.14.mlp.up_proj.lora_B.default.weight, model.layers.14.mlp.down_proj.lora_A.default.weight, model.layers.14.mlp.down_proj.lora_B.default.weight, model.layers.15.self_attn.q_proj.lora_A.default.weight, model.layers.15.self_attn.q_proj.lora_B.default.weight, model.layers.15.self_attn.k_proj.lora_A.default.weight, model.layers.15.self_attn.k_proj.lora_B.default.weight, model.layers.15.self_attn.v_proj.lora_A.default.weight, model.layers.15.self_attn.v_proj.lora_B.default.weight, model.layers.15.self_attn.o_proj.lora_A.default.weight, model.layers.15.self_attn.o_proj.lora_B.default.weight, model.layers.15.mlp.gate_proj.lora_A.default.weight, model.layers.15.mlp.gate_proj.lora_B.default.weight, model.layers.15.mlp.up_proj.lora_A.default.weight, model.layers.15.mlp.up_proj.lora_B.default.weight, model.layers.15.mlp.down_proj.lora_A.default.weight, model.layers.15.mlp.down_proj.lora_B.default.weight, model.layers.16.self_attn.q_proj.lora_A.default.weight, model.layers.16.self_attn.q_proj.lora_B.default.weight, model.layers.16.self_attn.k_proj.lora_A.default.weight, model.layers.16.self_attn.k_proj.lora_B.default.weight, model.layers.16.self_attn.v_proj.lora_A.default.weight, model.layers.16.self_attn.v_proj.lora_B.default.weight, model.layers.16.self_attn.o_proj.lora_A.default.weight, model.layers.16.self_attn.o_proj.lora_B.default.weight, model.layers.16.mlp.gate_proj.lora_A.default.weight, model.layers.16.mlp.gate_proj.lora_B.default.weight, model.layers.16.mlp.up_proj.lora_A.default.weight, model.layers.16.mlp.up_proj.lora_B.default.weight, model.layers.16.mlp.down_proj.lora_A.default.weight, model.layers.16.mlp.down_proj.lora_B.default.weight, model.layers.17.self_attn.q_proj.lora_A.default.weight, model.layers.17.self_attn.q_proj.lora_B.default.weight, model.layers.17.self_attn.k_proj.lora_A.default.weight, model.layers.17.self_attn.k_proj.lora_B.default.weight, model.layers.17.self_attn.v_proj.lora_A.default.weight, model.layers.17.self_attn.v_proj.lora_B.default.weight, model.layers.17.self_attn.o_proj.lora_A.default.weight, model.layers.17.self_attn.o_proj.lora_B.default.weight, model.layers.17.mlp.gate_proj.lora_A.default.weight, model.layers.17.mlp.gate_proj.lora_B.default.weight, model.layers.17.mlp.up_proj.lora_A.default.weight, model.layers.17.mlp.up_proj.lora_B.default.weight, model.layers.17.mlp.down_proj.lora_A.default.weight, model.layers.17.mlp.down_proj.lora_B.default.weight, model.layers.18.self_attn.q_proj.lora_A.default.weight, model.layers.18.self_attn.q_proj.lora_B.default.weight, model.layers.18.self_attn.k_proj.lora_A.default.weight, model.layers.18.self_attn.k_proj.lora_B.default.weight, model.layers.18.self_attn.v_proj.lora_A.default.weight, model.layers.18.self_attn.v_proj.lora_B.default.weight, model.layers.18.self_attn.o_proj.lora_A.default.weight, model.layers.18.self_attn.o_proj.lora_B.default.weight, model.layers.18.mlp.gate_proj.lora_A.default.weight, model.layers.18.mlp.gate_proj.lora_B.default.weight, model.layers.18.mlp.up_proj.lora_A.default.weight, model.layers.18.mlp.up_proj.lora_B.default.weight, model.layers.18.mlp.down_proj.lora_A.default.weight, model.layers.18.mlp.down_proj.lora_B.default.weight, model.layers.19.self_attn.q_proj.lora_A.default.weight, model.layers.19.self_attn.q_proj.lora_B.default.weight, model.layers.19.self_attn.k_proj.lora_A.default.weight, model.layers.19.self_attn.k_proj.lora_B.default.weight, model.layers.19.self_attn.v_proj.lora_A.default.weight, model.layers.19.self_attn.v_proj.lora_B.default.weight, model.layers.19.self_attn.o_proj.lora_A.default.weight, model.layers.19.self_attn.o_proj.lora_B.default.weight, model.layers.19.mlp.gate_proj.lora_A.default.weight, model.layers.19.mlp.gate_proj.lora_B.default.weight, model.layers.19.mlp.up_proj.lora_A.default.weight, model.layers.19.mlp.up_proj.lora_B.default.weight, model.layers.19.mlp.down_proj.lora_A.default.weight, model.layers.19.mlp.down_proj.lora_B.default.weight, model.layers.20.self_attn.q_proj.lora_A.default.weight, model.layers.20.self_attn.q_proj.lora_B.default.weight, model.layers.20.self_attn.k_proj.lora_A.default.weight, model.layers.20.self_attn.k_proj.lora_B.default.weight, model.layers.20.self_attn.v_proj.lora_A.default.weight, model.layers.20.self_attn.v_proj.lora_B.default.weight, model.layers.20.self_attn.o_proj.lora_A.default.weight, model.layers.20.self_attn.o_proj.lora_B.default.weight, model.layers.20.mlp.gate_proj.lora_A.default.weight, model.layers.20.mlp.gate_proj.lora_B.default.weight, model.layers.20.mlp.up_proj.lora_A.default.weight, model.layers.20.mlp.up_proj.lora_B.default.weight, model.layers.20.mlp.down_proj.lora_A.default.weight, model.layers.20.mlp.down_proj.lora_B.default.weight, model.layers.21.self_attn.q_proj.lora_A.default.weight, model.layers.21.self_attn.q_proj.lora_B.default.weight, model.layers.21.self_attn.k_proj.lora_A.default.weight, model.layers.21.self_attn.k_proj.lora_B.default.weight, model.layers.21.self_attn.v_proj.lora_A.default.weight, model.layers.21.self_attn.v_proj.lora_B.default.weight, model.layers.21.self_attn.o_proj.lora_A.default.weight, model.layers.21.self_attn.o_proj.lora_B.default.weight, model.layers.21.mlp.gate_proj.lora_A.default.weight, model.layers.21.mlp.gate_proj.lora_B.default.weight, model.layers.21.mlp.up_proj.lora_A.default.weight, model.layers.21.mlp.up_proj.lora_B.default.weight, model.layers.21.mlp.down_proj.lora_A.default.weight, model.layers.21.mlp.down_proj.lora_B.default.weight, model.layers.22.self_attn.q_proj.lora_A.default.weight, model.layers.22.self_attn.q_proj.lora_B.default.weight, model.layers.22.self_attn.k_proj.lora_A.default.weight, model.layers.22.self_attn.k_proj.lora_B.default.weight, model.layers.22.self_attn.v_proj.lora_A.default.weight, model.layers.22.self_attn.v_proj.lora_B.default.weight, model.layers.22.self_attn.o_proj.lora_A.default.weight, model.layers.22.self_attn.o_proj.lora_B.default.weight, model.layers.22.mlp.gate_proj.lora_A.default.weight, model.layers.22.mlp.gate_proj.lora_B.default.weight, model.layers.22.mlp.up_proj.lora_A.default.weight, model.layers.22.mlp.up_proj.lora_B.default.weight, model.layers.22.mlp.down_proj.lora_A.default.weight, model.layers.22.mlp.down_proj.lora_B.default.weight, model.layers.23.self_attn.q_proj.lora_A.default.weight, model.layers.23.self_attn.q_proj.lora_B.default.weight, model.layers.23.self_attn.k_proj.lora_A.default.weight, model.layers.23.self_attn.k_proj.lora_B.default.weight, model.layers.23.self_attn.v_proj.lora_A.default.weight, model.layers.23.self_attn.v_proj.lora_B.default.weight, model.layers.23.self_attn.o_proj.lora_A.default.weight, model.layers.23.self_attn.o_proj.lora_B.default.weight, model.layers.23.mlp.gate_proj.lora_A.default.weight, model.layers.23.mlp.gate_proj.lora_B.default.weight, model.layers.23.mlp.up_proj.lora_A.default.weight, model.layers.23.mlp.up_proj.lora_B.default.weight, model.layers.23.mlp.down_proj.lora_A.default.weight, model.layers.23.mlp.down_proj.lora_B.default.weight\n",
      "WARNING:lm-eval:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "WARNING:lm-eval:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "INFO:lm-eval:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "INFO:lm-eval:Using pre-initialized model\n",
      "INFO:lm-eval:Setting fewshot random generator seed to 1234\n",
      "INFO:lm-eval:Building contexts for mathqa on rank 0...\n",
      "100%|██████████| 2985/2985 [00:01<00:00, 2070.12it/s]\n",
      "INFO:lm-eval:Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|          | 0/14925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto:1. Detecting largest batch size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests:   0%|          | 1/14925 [00:01<6:56:07,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined largest batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 14925/14925 [00:17<00:00, 868.45it/s] \n",
      "WARNING:lm-eval:Failed to get model SHA for Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (k_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (v_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (o_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (up_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (down_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=4864, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4864, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>: 'Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (k_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (v_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=128, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (o_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (up_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=896, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4864, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (down_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=4864, out_features=896, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4864, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=896, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-0.5B-math-SFT-Improved-mc Results:\n",
      "  Accuracy: 0.2874 (+/- 0.0083)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28743718592964823, 0.008284830813404314)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qwen2.5-0.5B SFT Improved (MC) 모델 평가 (03_sft_training_improved.ipynb)\n",
    "evaluate_model(\n",
    "    model_id_or_path=SFT_IMPROVED_MODEL_05B_PATH,\n",
    "    model_name=\"Qwen2.5-0.5B-math-SFT-Improved-mc\",\n",
    "    is_local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 결과 요약 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MathQA Evaluation Results Summary\n",
      "============================================================\n",
      "                            Model  Accuracy  Std Error\n",
      "              Qwen2.5-0.5B (Base)  0.287437   0.008285\n",
      "            Qwen2.5-0.5B-math-SFT  0.288442   0.008293\n",
      "            Qwen2.5-0.5B-Instruct  0.290117   0.008308\n",
      "              Qwen2.5-1.5B (Base)  0.346064   0.008709\n",
      "            Qwen2.5-1.5B-math-SFT  0.297822   0.008371\n",
      "            Qwen2.5-1.5B-Instruct  0.337353   0.008655\n",
      "Qwen2.5-0.5B-math-SFT-Improved-mc  0.287437   0.008285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': name,\n",
    "        'Accuracy': data['accuracy'],\n",
    "        'Std Error': data['acc_stderr'],\n",
    "    }\n",
    "    for name, data in all_results.items()\n",
    "])\n",
    "\n",
    "# 정렬 순서 정의\n",
    "order = [\n",
    "    'Qwen2.5-0.5B (Base)',\n",
    "    'Qwen2.5-0.5B-math-SFT',\n",
    "    'Qwen2.5-0.5B-math-SFT-Improved',\n",
    "    'Qwen2.5-0.5B-Instruct',\n",
    "    'Qwen2.5-1.5B (Base)',\n",
    "    'Qwen2.5-1.5B-math-SFT',\n",
    "    'Qwen2.5-1.5B-Instruct',\n",
    "]\n",
    "\n",
    "# 정렬\n",
    "results_df['sort_order'] = results_df['Model'].map({name: i for i, name in enumerate(order)})\n",
    "results_df = results_df.sort_values('sort_order').drop('sort_order', axis=1).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MathQA Evaluation Results Summary\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Performance Improvement Analysis\n",
      "============================================================\n",
      "\n",
      "[Qwen2.5-0.5B]\n",
      "  Base Model Accuracy:     0.2874\n",
      "  SFT Model Accuracy:      0.2884\n",
      "  Absolute Improvement:    +0.10%p\n",
      "  Relative Improvement:    +0.35%\n",
      "  Instruct Model Accuracy: 0.2901\n",
      "  SFT vs Instruct:         -0.17%p\n",
      "\n",
      "[Qwen2.5-1.5B]\n",
      "  Base Model Accuracy:     0.3461\n",
      "  SFT Model Accuracy:      0.2978\n",
      "  Absolute Improvement:    -4.82%p\n",
      "  Relative Improvement:    -13.94%\n",
      "  Instruct Model Accuracy: 0.3374\n",
      "  SFT vs Instruct:         -3.95%p\n"
     ]
    }
   ],
   "source": [
    "# 성능 향상 분석\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Performance Improvement Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 0.5B 모델 분석\n",
    "if 'Qwen2.5-0.5B (Base)' in all_results and 'Qwen2.5-0.5B-math-SFT' in all_results:\n",
    "    base_05b = all_results['Qwen2.5-0.5B (Base)']['accuracy']\n",
    "    sft_05b = all_results['Qwen2.5-0.5B-math-SFT']['accuracy']\n",
    "    improvement_05b = (sft_05b - base_05b) * 100\n",
    "    relative_improvement_05b = ((sft_05b - base_05b) / base_05b) * 100 if base_05b > 0 else 0\n",
    "    \n",
    "    print(f\"\\n[Qwen2.5-0.5B]\")\n",
    "    print(f\"  Base Model Accuracy:     {base_05b:.4f}\")\n",
    "    print(f\"  SFT Model Accuracy:      {sft_05b:.4f}\")\n",
    "    print(f\"  Absolute Improvement:    {improvement_05b:+.2f}%p\")\n",
    "    print(f\"  Relative Improvement:    {relative_improvement_05b:+.2f}%\")\n",
    "\n",
    "if 'Qwen2.5-0.5B-math-SFT-Improved' in all_results:\n",
    "    sft_improved_05b = all_results['Qwen2.5-0.5B-math-SFT-Improved']['accuracy']\n",
    "    print(f\"  SFT Improved Accuracy:   {sft_improved_05b:.4f}\")\n",
    "\n",
    "if 'Qwen2.5-0.5B-Instruct' in all_results:\n",
    "    instruct_05b = all_results['Qwen2.5-0.5B-Instruct']['accuracy']\n",
    "    print(f\"  Instruct Model Accuracy: {instruct_05b:.4f}\")\n",
    "    if 'Qwen2.5-0.5B-math-SFT' in all_results:\n",
    "        sft_vs_instruct_05b = (sft_05b - instruct_05b) * 100\n",
    "        print(f\"  SFT vs Instruct:         {sft_vs_instruct_05b:+.2f}%p\")\n",
    "    if 'Qwen2.5-0.5B-math-SFT-Improved' in all_results:\n",
    "        sft_improved_vs_instruct = (sft_improved_05b - instruct_05b) * 100\n",
    "        print(f\"  SFT Improved vs Instruct: {sft_improved_vs_instruct:+.2f}%p\")\n",
    "\n",
    "# 1.5B 모델 분석\n",
    "if 'Qwen2.5-1.5B (Base)' in all_results and 'Qwen2.5-1.5B-math-SFT' in all_results:\n",
    "    base_15b = all_results['Qwen2.5-1.5B (Base)']['accuracy']\n",
    "    sft_15b = all_results['Qwen2.5-1.5B-math-SFT']['accuracy']\n",
    "    improvement_15b = (sft_15b - base_15b) * 100\n",
    "    relative_improvement_15b = ((sft_15b - base_15b) / base_15b) * 100 if base_15b > 0 else 0\n",
    "    \n",
    "    print(f\"\\n[Qwen2.5-1.5B]\")\n",
    "    print(f\"  Base Model Accuracy:     {base_15b:.4f}\")\n",
    "    print(f\"  SFT Model Accuracy:      {sft_15b:.4f}\")\n",
    "    print(f\"  Absolute Improvement:    {improvement_15b:+.2f}%p\")\n",
    "    print(f\"  Relative Improvement:    {relative_improvement_15b:+.2f}%\")\n",
    "\n",
    "if 'Qwen2.5-1.5B-Instruct' in all_results:\n",
    "    instruct_15b = all_results['Qwen2.5-1.5B-Instruct']['accuracy']\n",
    "    print(f\"  Instruct Model Accuracy: {instruct_15b:.4f}\")\n",
    "    if 'Qwen2.5-1.5B-math-SFT' in all_results:\n",
    "        sft_vs_instruct_15b = (sft_15b - instruct_15b) * 100\n",
    "        print(f\"  SFT vs Instruct:         {sft_vs_instruct_15b:+.2f}%p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 준비\n",
    "models_05b = ['Base', 'SFT', 'SFT-Improved', 'Instruct']\n",
    "models_15b = ['Base', 'SFT', 'SFT-Improved', 'Instruct']\n",
    "\n",
    "acc_05b = [\n",
    "    all_results.get('Qwen2.5-0.5B (Base)', {}).get('accuracy', 0),\n",
    "    all_results.get('Qwen2.5-0.5B-math-SFT', {}).get('accuracy', 0),\n",
    "    all_results.get('Qwen2.5-0.5B-math-SFT-Improved', {}).get('accuracy', 0),\n",
    "    all_results.get('Qwen2.5-0.5B-Instruct', {}).get('accuracy', 0),\n",
    "]\n",
    "\n",
    "acc_15b = [\n",
    "    all_results.get('Qwen2.5-1.5B (Base)', {}).get('accuracy', 0),\n",
    "    all_results.get('Qwen2.5-1.5B-math-SFT', {}).get('accuracy', 0),\n",
    "    all_results.get('Qwen2.5-1.5B-math-SFT-Improved', {}).get('accuracy', 0),\n",
    "    all_results.get('Qwen2.5-1.5B-Instruct', {}).get('accuracy', 0),\n",
    "]\n",
    "\n",
    "# 그래프 생성\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 0.5B 모델 그래프\n",
    "colors_05b = ['#3498db', '#e74c3c', '#9b59b6', '#2ecc71']\n",
    "bars1 = axes[0].bar(models_05b, acc_05b, color=colors_05b, edgecolor='black', linewidth=1.2)\n",
    "axes[0].set_title('Qwen2.5-0.5B Models - MathQA Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_ylim(0, max(max(acc_05b), max(acc_15b)) * 1.2)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 값 표시\n",
    "for bar, acc in zip(bars1, acc_05b):\n",
    "    if acc > 0:\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{acc:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 1.5B 모델 그래프\n",
    "colors_15b = ['#3498db', '#e74c3c', '#9b59b6', '#2ecc71']\n",
    "bars2 = axes[1].bar(models_15b, acc_15b, color=colors_15b, edgecolor='black', linewidth=1.2)\n",
    "axes[1].set_title('Qwen2.5-1.5B Models - MathQA Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_ylim(0, max(max(acc_05b), max(acc_15b)) * 1.2)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 값 표시\n",
    "for bar, acc in zip(bars2, acc_15b):\n",
    "    if acc > 0:\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{acc:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 범례 추가\n",
    "fig.legend(['Base Model', 'SFT (Our Method)', 'SFT Improved (MC)', 'Instruct (Official)'], \n",
    "           loc='upper center', ncol=3, fontsize=11, bbox_to_anchor=(0.5, 1.02))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mathqa_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "# 결과 JSON 저장\n",
    "with open('evaluation_results.json', 'w') as f:\n",
    "    json.dump(all_results, f, indent=2, default=str)\n",
    "\n",
    "print(\"Results saved to evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Markdown Format Results (for report)\n",
      "============================================================\n",
      "\n",
      "## MathQA Evaluation Results\n",
      "\n",
      "| Model | Accuracy | Std Error |\n",
      "|-------|----------|----------|\n",
      "| Qwen2.5-0.5B (Base) | 0.2874 | 0.0083 |\n",
      "| Qwen2.5-0.5B-math-SFT | 0.2884 | 0.0083 |\n",
      "| Qwen2.5-0.5B-Instruct | 0.2901 | 0.0083 |\n",
      "| Qwen2.5-1.5B (Base) | 0.3461 | 0.0087 |\n",
      "| Qwen2.5-1.5B-math-SFT | 0.2978 | 0.0084 |\n",
      "| Qwen2.5-1.5B-Instruct | 0.3374 | 0.0087 |\n",
      "| Qwen2.5-0.5B-math-SFT-Improved-mc | 0.2874 | 0.0083 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Markdown 형식 결과 출력\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Markdown Format Results (for report)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "markdown_output = \"\"\"\n",
    "## MathQA Evaluation Results\n",
    "\n",
    "| Model | Accuracy | Std Error |\n",
    "|-------|----------|----------|\n",
    "\"\"\"\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    markdown_output += f\"| {row['Model']} | {row['Accuracy']:.4f} | {row['Std Error']:.4f} |\\n\"\n",
    "\n",
    "print(markdown_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Google Drive에 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Google Drive!\n"
     ]
    }
   ],
   "source": [
    "# 결과 파일 Google Drive에 복사\n",
    "!mkdir -p /content/drive/MyDrive/llm-math-models/\n",
    "!cp evaluation_results.json /content/drive/MyDrive/llm-math-models/\n",
    "!cp mathqa_results.png /content/drive/MyDrive/llm-math-models/\n",
    "\n",
    "print(\"Results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 SFT Improved (MC objective) 모델 평가\n",
    "\n",
    "03_sft_training_improved.ipynb에서 학습 후 Google Drive에 업로드한 모델을 평가합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
